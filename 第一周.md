# 1. 引言（Introduction to Machine Learning）

## 1.1 什么是机器学习？

第一个提出机器学习的是Arthur Samuel，她将机器学习定义为一种研究领域，使计算机能够在没有明确编程的情况下进行学习。在20世纪50年代，她写了一个跳棋游戏程序，使得电脑在跟电脑自己下棋的过程中进行自我训练，最终成为一个好的棋手。

机器学习的两种主要类型是监督学习（supervised learning）和非监督学习（unsupervised learning）。到目前为止，最常用的学习算法类型是监督学习、无监督学习和推荐系统（recommender systems）。接下来会对这些定义进行具体介绍。

## 1.2 监督学习（supervised learning）

监督学习是指学习x到y或输入到输出映射的算法。

监督学习的关键特征是你需要提供学习算法例子来学习。通过使用带标签的数据集训练算法，以达到准确分类数据或预测结果的目的。

><small>今天最有利润的监督学习形式可能是用于在线广告。几乎所有的大型在线广告平台都有一个学习算法，它会输入关于广告的一些信息和关于你的一些信息，然后试图弄清楚你是否会点击那个广告。因为通过向你展示广告，他们只是更有可能点击，对于这些大型在线广告平台来说，每一次点击都是收入，这实际上为这些公司带来了很多收入。这是我曾经做过很多工作的东西，也许不是最鼓舞人心的应用，但它确实对今天一些国家的经济产生了重大影响。<br> <br>或者，如果你想制造一辆自动驾驶汽车，学习算法会把一张图像和其他传感器(如雷达或其他东西)的一些信息作为输入，然后尝试输出其他汽车的位置，比如，其他汽车的位置，这样你的自动驾驶汽车就可以安全地绕过其他汽车。<br> <br>或者以制造业为例，你可以让一个学习算法把一个制造出来的产品的图片作为输入，比如一个刚刚从生产线上下线的手机，然后让学习算法输出产品中是否有划痕、凹痕或其他缺陷。这被称为视觉检查，它可以帮助制造商减少或防止产品缺陷。</small>


在所有这些应用中，你将首先用输入x和正确答案的例子来训练你的模型，也就是标签y。在模型从这些输入、输出或(x, y)中学习之后，他们可以使用一个全新的输入x，它从未见过的东西，并尝试产生相应的输出y。让我们更深入地研究一个具体的例子。

### 1.2.1 回归算法


![[Pasted image 20230131165804.png]]
假设你想根据房子的大小来预测房价。你收集了一些数据，然后把数据画出来，它是这样的。横轴上是房子的面积，单位是平方英尺。纵轴是房子的价格，以几千美元为单位。有了这些数据，假设一个朋友想知道他们750平方英尺的房子的价格。学习算法如何帮助你?学习算法可能会做的一件事是，对于数据的直线，从直线上读取，看起来你朋友的房子可以卖到15万美元。但是拟合直线并不是你唯一可以使用的学习算法。对于这个应用程序，还有其他更好的方法。

![[Pasted image 20230131170014.png]]

现在看起来拟合曲线似乎是更好的选择，那么看起来，你朋友的房子可以卖到接近20万美元。

在这张幻灯片上显示的是监督学习的一个例子。因为我们给了算法一个数据集，在这个数据集里，所谓的正确答案，也就是标签，或者说正确的价格y，是给图上每一栋房子的。学习算法的任务是产生更多这样的正确答案，特别是预测其他房子的可能价格，比如你朋友的房子。

这种房价预测是一种特殊类型的监督学习，称为回归。通过回归，我们试图从无限个可能的数字中预测一个数字，这就是监督学习，学习输入，输出，或者x到y的映射。你在这个视频中看到了一个回归的例子，回归这个词的意思是，**我们在试着推测出这一系列连续值属性**。但是还有第二种主要的监督学习问题叫做分类。

### 1.2.2 分类算法

以乳腺癌检测作为例子。假设你正在构建一个机器学习系统，这样医生就可以有一个诊断工具来检测乳腺癌。利用病人的医疗记录，你的机器学习系统试图找出一个肿块是恶性的，意味着癌变或危险。在这个例子中用0表示良性的，用1表示恶性的。

![[Pasted image 20230131171022.png]]

然后可以将数据绘制在这样的图形上，其中横轴表示肿瘤的大小，垂直轴只有两个值(0或1)，这取决于肿瘤是良性0还是恶性1。这与回归不同的一个原因是，**我们试图只预测少量可能的输出或类别**。

在这种情况下，有两个可能的输出0或1，良性或恶性。这不同于回归，回归试图预测任何数字，所有无限个可能的数字。因此，只有两种可能的输出就是这种分类的原因。

当你解释数字时，分类与回归的不同之处在于，分类预测的是一个小的、有限的、可能的输出类别集，如0、1和2，而不是介于0.5或1.7之间的所有可能的数字。

![[Pasted image 20230131171318.png]]

也可以使用多个输入值来预测输出。举个例子，除了知道肿瘤的大小，你还知道每个病人的年龄。您的新数据集现在有两个输入，年龄和肿瘤大小。在这个新的数据集中，我们将用圆圈来表示良性肿瘤的患者，用十字来表示恶性肿瘤的患者。因此，当有新病人来看病时，医生可以测量病人的肿瘤大小，并记录病人的年龄。鉴于此，我们如何预测这个病人的肿瘤是良性还是恶性。假设有这样的一天，学习算法可能会找到一些边界，将恶性肿瘤和良性肿瘤分开。所以学习算法必须决定如何在这些数据中拟合出一条**边界线**。学习算法发现的边界线将帮助医生进行诊断。在这种情况下，肿瘤更可能是良性的。

> <small>你想用无限多种特征，好让你的算法可以利用大量的特征，或者说线索来做推测。那你怎么处理无限多个特征，甚至怎么存储这些特征都存在问题，你电脑的内存肯定不够用。我们以后会讲一个算法，叫<b>支持向量机</b>，里面有一个巧妙的数学技巧，能让计算机处理无限多个特征。</small>

## 1.3 无监督学习（unsupervised learning）

![[Pasted image 20230131175401.png]]

在无监督学习中，我们已知的数据。看上去有点不一样，不同于监督学习的数据的样子， 即无监督学习中没有任何的标签或者是有相同的标签或者就是没标签。所以我们已知数据 集，却不知如何处理，也未告知每个数据点是什么。别的都不知道，就是一个数据集。你能 从数据中找到某种结构吗？针对数据集，无监督学习就能判断出数据有两个不同的聚集簇。 这是一个，那是另一个，二者不同。是的，无监督学习算法可能会把这些数据分成两个不同 的簇。所以叫做聚类算法。

聚类应用的一个例子就是在谷歌新闻中。谷歌新闻每天都在收集非常多的网络的新闻内容。 它再将这些新闻分组，组成有关联的新闻。所以谷歌新闻做的就是搜索非常多的新闻事件， 自动地把它们聚类到一起。所以，这些新闻事件全是同一主题的，所以显示到一起。

![[Pasted image 20230131175624.png]]

其中就有基因学的理解应用。一个 DNA 微观数据的例子。基本思想是输入一组不同个 体，对其中的每个个体，你要分析出它们是否有一个特定的基因。技术上，你要分析多少特 定基因已经表达。所以这些颜色，红，绿，灰等等颜色，这些颜色展示了相应的程度，即不 同的个体是否有着一个特定的基因。你能做的就是运行一个聚类算法，把个体聚类到不同的 类或不同类型的组（人）。

**这是一种无监督学习算法，它获取没有标签的数据，并试图自动将它们分组到集群中**。除了聚类，还有其他类型的无监督学习。

## 1.4 回归模型（regression model）

### 1.4.1 线性回归模型（Linear regression model）

让我们从一个可以使用线性回归解决的问题开始。假设你想根据房子的大小来预测房子的价格。我们将使用来自美国波特兰的房屋大小和价格数据集。这里我们有一个图表，横轴是房子的大小，单位是平方英尺，纵轴是房子的价格，单位是几千美元。让我们继续绘制数据集中不同房屋的数据点。这里的每一个数据点，每一个小叉都是一个房子的大小和最近的售价。
![[Pasted image 20230131182925.png]]

现在，假设你是波特兰的一名房地产经纪人，你正在帮助一位客户出售她的房子。她是在问你，你觉得这房子我能卖多少钱？这个数据集也许能帮你估计一下她能卖多少钱。你从测量房子的大小开始，结果是房子有1250平方英尺。你觉得这房子能卖多少钱？你可以做的一件事是，你可以从这个数据集建立一个线性回归模型。您的模型将拟合数据的直线，它可能看起来像这样。根据这条与数据匹配的直线，你可以看到房子是1250平方英尺，它将与这里的最佳拟合线相交，如果你追踪到左边的纵轴，你可以看到价格可能在这里，大约22万美元。

这就是所谓的监督学习模型的一个例子。我们称之为监督学习，因为你首先是通过给出一个有正确答案的数据来训练一个模型，因为你得到了房子的模型示例，包括房子的大小，以及模型应该预测的每套房子的价格。这里是价格，也就是说，数据集中每个房子的正确答案都给出了。

这种线性回归模型是一种特殊类型的监督学习模型。它被称为回归模型，因为**它预测数字作为产出**，如美元价格。

![[Pasted image 20230131183029.png]]

在回归中，模型可以输出无限多个可能的数字。除了将这些数据可视化为左边的图表，还有一种方法可以很有用，那就是右边的数据表。数据由一组输入组成。这就是房子的大小，也就是这一列。它也有输出。你要预测价格，也就是这一列。请注意，水平轴和垂直轴对应这两列，大小和价格。假设这个数据表中有47行，那么左边的图上就有47个小叉，每个叉对应表中的一行。

**专业术语：**

![[Pasted image 20230131184220.png]]

- **训练集**：用来**训练模型的数据集**叫做**训练集**。您客户的房子不在这个数据集中，因为它还没有出售，所以没有人知道价格是多少。为了预测你客户的房子的价格，你首先训练你的模型从训练集中学习，然后这个模型就可以预测你客户的房子的价格。
- ${x - }$**输入变量/特征**：在机器学习中，这里**表示输入的标准符号是小写的x**，我们称其为**输入变量**，也称为**特征或输入特征**。例如，对于训练集中的第一个房子，x是房子的大小，所以x等于2104。
-  ${y - }$**输出变量/目标变量**：用来表示你要预测的输出变量的标准符号，有时也被称为**目标变量**，是小写的y，这里，y是房子的价格，在第一个训练例子中，它等于400，所以y等于400。
-  ${m - }$**训练样本数量**：数据集每所房子都有一行，在这个训练集中，有47行，每行代表一个不同的**训练示例**。我们用小写的**m**表示**训练样本的总数**，这里m等于47。
- ${(x, y) - }$**单个训练示例**：为了表示单个训练示例，我们将使用括号x, y。对于第一个训练示例(x, y)，这对数字是(2104,400)。
- ${(x^{(i)}, y^{(i)}) - }$**特定训练示例**：第i个训练示例，这将对应于左侧表格中的特定行，我将在括号中使用符号x上标，在括号I中使用符号I, y上标。上标告诉我们这是第I个训练示例。

![[Pasted image 20230131191805.png]]

回想一下，监督学习中的训练集既包括输入特征，比如房子的大小，也包括输出目标，比如房子的价格。输出目标是我们将从中学习的模型的正确答案。为了训练模型，你把训练集、输入特征和输出目标都输入到学习算法中。然后你的监督学习算法会产生一些函数。我们把这个函数写成小写的f，有时也表示为h。

f的作用是得到一个新的输入x和输出，然后估计或预测，它叫做$\hat{y}$。在机器学习中，惯例是$\hat{y}$是y的估计值或预测值。函数f称为模型。X被称为输入或输入特征，模型的输出是预测，$\hat{y}$。

模型的预测是y的估计值。当符号只是字母y时，则它指的是目标，即训练集中的实际真实值。相反，$\hat{y}$是估计值。它可能是也可能不是实际的真实值。如果你在帮助你的客户卖房子，房子的真实价格在他们卖之前是不知道的。

现在，当我们设计一个学习算法时，一个关键问题是，我们如何表示函数f？换句话说，我们要用什么数学公式来计算f?现在，我们坚持f是一条直线。

![[Pasted image 20230131192342.png]]

你的函数可以写成$f_{w,b}(x) = wx + b$。但是现在，只需要知道w和b是数字，为w和b选择的值将决定基于输入特征x的预测，$\hat{y}$。这个$f_{w,b}(x)$意味着f是一个以x为输入的函数，根据w和b的值，f将输出预测$\hat{y}$的某个值。作为另一种写法，有时只写f(x)。

让我们把训练集画在图上，输入特征x在横轴上，输出目标y在纵轴上。

记住，算法从这些数据中学习并生成最拟合的直线，比如这条。这个线性函数$f_{w,b}(x) = wx + b$。我们可以降低w和b和只写$f(x) = wx + b$。这是这个函数是要预测y的值,使用一个简化的函数x。

有时候你也想拟合更复杂的非线性函数，比如这样的曲线。但由于这个线性函数相对简单，易于处理，让我们使用一条线作为基础，最终将帮助你得到更复杂的非线性模型。这个模型有个名字，叫做线性回归。更具体地说，这是**单变量线性回归**。

![[Pasted image 20230131194105.png]]

为了实现线性回归，第一个关键步骤是首先定义一个成本函数。成本函数会告诉我们模型的表现如何，这样我们就能让它做得更好。你有一个包含输入特征x和输出目标y的训练集。你要用来适应这个训练集的模型是这个线性函数$f_{w,b}(x) = wx + b$。w和b被称为模型的参数。在机器学习中，模型的参数是你在训练过程中可以调整的变量，以改进模型。有时你也会听到参数w和b被称为系数或权重。根据你选择的w和b的值你会得到一个不同的函数f(x)它会在图上生成一条不同的直线。

![[Pasted image 20230131194427.png]]

第一个例子，函数f (x)等于0 * (x + 1.5)所以f总是一个常数。y的估计值总是1.5，$\hat{y}$总是等于b这里b也被称为y截距。
第二个例子，如果w = 0.5且b = 0，则f (x) = 0.5 * x。当x = 0时，预测结果也是0，当x = 2时，预测结果是0.5 * 2，即1。得到一条这样的直线，斜率是0.5。w的值表示直线的斜率，也就是0.5。
最后，如果w = 0.5，b = 1，那么f (x) = 0.5 (x + 1)。当x = 0时，f (x) = b，也就是1。所以这条直线与纵轴在b处相交，即y轴截距。当x = 2时，f (x) = 2，直线是这样的。同样，这个斜率是0.5除以1所以w的值给你的斜率是0.5。

回想一下，你有一个类似于这里显示的训练集。在线性回归中，你要做的是为参数w和b选择值，这样你从函数f中得到的直线就能很好地符合数据。比如这条线。


比如这个点是由${(x^{(i)}, y^{(i)})}$定义的，其中y是目标。对于给定的输入$x^i$，函数f也给出了y的预测值，它对y的预测值就是这里的$y^i$。对于我们选择的模型$f_{w,b}(x^{(i)}) = wx^{(i)} + b$，换一种说法，预测$\hat{y}^{(i)} = f_(w,b)(x^{(i)})$。


现在的问题是如何找到w和b的值使得预测$y^i$接近真实的目标$\hat{y}^{i}$。要回答这个问题，让我们先来看看如何衡量一条线与训练数据的拟合程度。为此，我们要构造一个成本函数。

![[Pasted image 20230131200750.png]]

1. 成本函数使用预测$\hat{y}$，并将其与目标y进行比较，即$\hat{y} - y$。这种差被称为误差，我们测量的是预测距离目标的距离。
2. 接下来，让我们计算这个误差的平方。同时，我们还想计算训练集中不同训练例子i的这一项。当测量误差时，例如i，我们会计算这个平方误差项。
3. 最后，我们想要测量整个训练集的误差。特别地，让我们像这样把平方误差加起来。我们从i = 1 2 3一直加到m，m是训练样本的数量，这个数据集是47。
4. 注意，如果我们有更多的训练示例，m就会更大，成本函数就会计算出更大的数字。
5. 为了建立一个不会随着训练集规模变大而自动变大的代价函数，我们将计算**平均平方误差**，而不是总平方误差，我们通过像这样**除以m**来计算。
6. 按照惯例，机器学习人员使用的代价函数实际上是除以2乘以m。额外的除以2只是为了让我们后面的一些计算看起来更整洁，但无论你是否包括这个除以2，代价函数仍然有效。

这也叫**平方误差代价函数**，之所以叫这个是因为要取这些误差项的平方。